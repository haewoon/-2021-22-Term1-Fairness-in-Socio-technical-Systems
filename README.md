# 2021-22-Term1-Fairness-in-Socio-technical-Systems

This repository is for archiving course materials for IS472: Fairness in Socio-technial Systems (2021-22 Term1), School of Computing and Information Systems, Singapore Management University.

Instructor: [KWAK Haewoon](https://soda-labo.github.io/)

# Topics to be Covered
| Week | Description | Slides | Group activity |
| --- | --- | :---: | --- |
| **W1** | Introduction<br/><img src="https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/blob/main/Week%201%20-%20Introduction.png?raw=true" width="480"> | [PDF](https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%201%20-%20Introduction.pdf) | 1. [Colab - Twitter's image cropping algorithm](https://github.com/haewoon/lab-image-crop-analysis) <br/> 2. Algorithmic curations in your favorite apps |
| **W2** | Case studies of measuring fairness and biase (I)<br/><img src="https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/blob/main/Week%202%20-%20Case%20studies%20of%20measuring%20fairness%20and%20bias%20(I).png?raw=true" width="480"> | [PDF](https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%202%20-%20Case%20studies%20of%20measuring%20fairness%20and%20bias%20(I).pdf) | 1. Google Teachable Machine <br/>2. High- and low-resource hospitals' EHRs|
| **W3** | Case studies of measuring fairness and biase (II)<br/><img src="https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/blob/main/Week%203%20-%20Case%20studies%20of%20measuring%20fairness%20and%20bias%20(II).png?raw=true" width="480"> | [PDF](https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%203%20-%20Case%20studies%20of%20measuring%20fairness%20and%20bias%20(II).pdf) | 1. WooClap: Ethical considerations in AI Healthcare <br/>2. Gender and racial stereotypes in image search|
| **W4** | Auditing algorithms<br/><img src="https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/blob/main/Week%204%20-%20Auditing%20algorithms.png?raw=true" width="480"> | [PDF](https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%204%20-%20Auditing%20algorithms.pdf) | 1. Design your audit study |
| **W5** | Bias in data and machine learning models (I)<br/><img src="https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/blob/main/Week%205%20-%20Bias%20in%20data%20and%20machine%20learning%20models%20(I).png?raw=true" width="480"> | [PDF](https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%205%20-%20Bias%20in%20data%20and%20machine%20learning%20models%20(I).pdf) | 1. Sharing your story about various cognitive biases|
| **W6** | Project consultation | | |
| **W7** | Project idea pitching | | |
| **W8** | Recess week | | |
| **W9** | Bias in data and machine learning models (II) <br/><img src="https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/blob/main/Week%209%20-%20Bias%20in%20data%20and%20machine%20learning%20models%20(II).png?raw=true" width="480"> | [PDF](https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%209%20-%20Bias%20in%20data%20and%20machine%20learning%20models%20(II).pdf) | 1. Inappropriate synsets in ImageNet<br/>2. Bias in word embeddings |
| **W10** | Interpretability of algorithmic systems <br/><img src="https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%2010%20-%20Interpretability%20of%20algorithmic%20systems.png" width="480"> | [PDF](https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%2010%20-%20Interpretability%20of%20algorithmic%20systems.pdf) | 1. Colab - Apply LIME into two NLP models |
| **W11** | Fairness mechanisms<br/><img src="https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%2011%20-%20Fairness%20mechanisms.png" width="480"> | [PDF](https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%2011%20-%20Fairness%20mechanisms.pdf) | 1. Error metrics in context<br/>2. WooClap: Is this algorithm fair? |
| **W12** | HCI perspective of fairness + Project consultation<br/><img src="https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%2012%20-%20HCI%20perspective%20of%20fairness.png" width="480"> | [PDF](https://github.com/haewoon/2021-22-Term1-Fairness-in-Socio-technical-Systems/raw/main/Week%2012%20-%20HCI%20perspective%20of%20fairness.pdf) | 1. Fairness metric in skin cancer prediction<br/>2. WooClap: Trade-off between accuracy and fairness | 
| **W13** | Project presentation | | |
| **W14** | Study week | | |
| **W15** | Final exam | | |

# (Optionalüôè) Reading list
**W1: Introduction**
- [Friedman, Batya, and Helen Nissenbaum. "Bias in computer systems." ACM Transactions on Information Systems (TOIS) 14.3 (1996): 330-347.](https://dl.acm.org/doi/10.1145/230538.230561)
- [Amazon Changed Search Algorithm in Ways That Boost Its Own Products, WSJ, 2019](https://www.wsj.com/articles/amazon-changed-search-algorithm-in-ways-that-boost-its-own-products-11568645345)
- [Else, Holly. "How to banish manels and manferences from scientific meetings." Nature 573.7773 (2019): 184-187.](https://www.nature.com/articles/d41586-019-02658-6)
- [Speedy Neural Networks for Smart Auto-Cropping of Images, Twitter Engineering blog, 2018](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2018/Smart-Auto-Cropping-of-Images)
- [Sharing learnings about our image cropping algorithm, Twitter Engineering blog, 2021](https://blog.twitter.com/engineering/en_us/topics/insights/2021/sharing-learnings-about-our-image-cropping-algorithm)
- [Facebook Apologizes After A.I. Puts ‚ÄòPrimates‚Äô Label on Video of Black Men, The New York Times, 2021](https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html)

**W2: Case studies of measuring fairness and biase (I) - Healthcare, Criminal system**
- [Price, I. I., and W. Nicholson. "Medical AI and contextual bias." (2019).](https://papers.ssrn.com/sol3/Papers.cfm?abstract_id=3347890)
- [IDx-DR - How It Works, IDx (YouTube)](https://www.youtube.com/watch?v=dWiF8THxf7Q)
- [Cirillo, Davide, et al. "Sex and gender differences and biases in artificial intelligence for biomedicine and healthcare." NPJ digital medicine 3.1 (2020): 1-11.](https://www.nature.com/articles/s41746-020-0288-5)
- [Martin, Lisa A., Harold W. Neighbors, and Derek M. Griffith. "The experience of symptoms of depression in men vs women: analysis of the National Comorbidity Survey Replication." JAMA psychiatry 70.10 (2013): 1100-1106.](https://jamanetwork.com/journals/jamapsychiatry/fullarticle/1733742)
- [Feiner, John R., John W. Severinghaus, and Philip E. Bickler. "Dark skin decreases the accuracy of pulse oximeters at low oxygen saturation: the effects of oximeter probe type and gender." Anesthesia & Analgesia 105.6 (2007): S18-S23.](https://pubmed.ncbi.nlm.nih.gov/18048893/)
- [Obermeyer, Ziad, et al. "Dissecting racial bias in an algorithm used to manage the health of populations." Science 366.6464 (2019): 447-453.](https://www.science.org/doi/10.1126/science.aax2342)
- [Larrazabal, Agostina J., et al. "Gender imbalance in medical imaging datasets produces biased classifiers for computer-aided diagnosis." Proceedings of the National Academy of Sciences 117.23 (2020): 12592-12594.](https://www.pnas.org/content/117/23/12592)
- [Machine Bias, ProPublica, 2016](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
- [How predictive policing software works, The Verge, 2016 (YouTube)](https://www.youtube.com/watch?v=YxvyeaL7NEM)
- [Lum, Kristian, and William Isaac. "To predict and serve?." Significance 13.5 (2016): 14-19.](https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1740-9713.2016.00960.x)

**W2: Case studies of measuring fairness and biase (II) - Hiring, Urban mobility, Immigration system, Web search, Wikipedia**
- [Peng, Andi, et al. "What you see is what you get? the impact of representation criteria on human bias in hiring." Proceedings of the AAAI Conference on Human Computation and Crowdsourcing. Vol. 7. No. 1. 2019.](https://ojs.aaai.org/index.php/HCOMP/article/view/5281)
- [Amazon scraps secret AI recruiting tool that showed bias against women, Reuters, 2018](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G)
- [Lambrecht, Anja, and Catherine Tucker. "Algorithmic bias? An empirical study of apparent gender-based discrimination in the display of STEM career ads." Management science 65.7 (2019): 2966-2981.](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2018.3093)
- [We tried the AI software companies like Goldman Sachs and Unilever use to analyze job applicants, Business Insider, 2017 (YouTube)](https://www.youtube.com/watch?v=QfuGRCmXmCs)
- [A face-scanning algorithm increasingly decides whether you deserve the job, The Washington Post, 2019](https://www.washingtonpost.com/technology/2019/10/22/ai-hiring-face-scanning-algorithm-increasingly-decides-whether-you-deserve-job/)
- [Heaven, Douglas. "Why Faces Don't Always Tell the Truth About Feelings." Nature 578.7796 (2020): 502-504.](https://www.nature.com/articles/d41586-020-00507-5)
- [Buolamwini, Joy, and Timnit Gebru. "Gender shades: Intersectional accuracy disparities in commercial gender classification." Conference on fairness, accountability and transparency. PMLR, 2018.](http://proceedings.mlr.press/v81/buolamwini18a.html?mod=article_inline)
- [Hutchinson, Ben, et al. "Social Biases in NLP Models as Barriers for Persons with Disabilities." Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 2020.](https://aclanthology.org/2020.acl-main.487/)
- [Illinois says you should know if AI is grading your online job interviews, Vox, 2020](https://www.vox.com/recode/2020/1/1/21043000/artificial-intelligence-job-applications-illinios-video-interivew-act)
- [Uber seems to offer better service in areas with more white people. That raises some tough questions. The Washington Post, 2016](https://www.washingtonpost.com/news/wonk/wp/2016/03/10/uber-seems-to-offer-better-service-in-areas-with-more-white-people-that-raises-some-tough-questions/)
- [Ge, Yanbo, et al. Racial and gender discrimination in transportation network companies. No. w22776. National Bureau of Economic Research, 2016.](https://www.nber.org/papers/w22776)
- [Amazon Doesn‚Äôt Consider the Race of Its Customers. Should It?, Bloomberg, 2016](https://www.bloomberg.com/graphics/2016-amazon-same-day/)
- [We won! Home Office to stop using racist visa algorithm, JCWI, 2020](https://www.jcwi.org.uk/news/we-won-home-office-to-stop-using-racist-visa-algorithm)
- ['Highly concerning': picture books bias worsens as female characters stay silent, The Guardian, 2019](https://www.theguardian.com/books/2019/jun/13/highly-concerning-picture-books-bias-worsens-as-female-characters-stay-silent)
- [Kay, Matthew, Cynthia Matuszek, and Sean A. Munson. "Unequal representation and gender stereotypes in image search results for occupations." Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. 2015.](https://dl.acm.org/doi/10.1145/2702123.2702520)
- [Wagner, Claudia, et al. "It's a man's Wikipedia? Assessing gender inequality in an online encyclopedia." Ninth international AAAI conference on web and social media. 2015.](https://arxiv.org/abs/1501.06307)
- [Wade, Jess, and Maryam Zaringhalam. "Why we‚Äôre editing women scientists onto Wikipedia." Nature 14 (2018).](https://www.nature.com/articles/d41586-018-05947-8)
- [Sun, Jiao, and Nanyun Peng. "Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia." Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 2021.](https://aclanthology.org/2021.acl-short.45/)
- [Koenecke, Allison, et al. "Racial disparities in automated speech recognition." Proceedings of the National Academy of Sciences 117.14 (2020): 7684-7689.](https://www.pnas.org/content/117/14/7684)
- [An, Jisun, and Haewoon Kwak. "Gender and racial diversity in commercial brands‚Äô advertising images on social media." International Conference on Social Informatics. Springer, Cham, 2019.](https://arxiv.org/abs/1908.01352)
